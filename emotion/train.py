import torch
import torch.nn as nn
import time
from tqdm import tqdm

def run_epoch(model, loader, optimizer, device, mode="train"):
    """
    1 Epoch ë™ì•ˆ í•™ìŠµ(Train) ë˜ëŠ” ê²€ì¦(Val)ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    if mode == "train":
        model.train()
    else:
        model.eval()

    total = 0
    correct = 0
    total_loss = 0.0
    
    criterion = nn.CrossEntropyLoss()
    start_time = time.time()

    with torch.set_grad_enabled(mode == "train"):
        # dynamic_ncols=Trueë¡œ ì°½ í¬ê¸° ìë™ ì¡°ì ˆ
        pbar = tqdm(loader, desc=mode.upper(), leave=False, dynamic_ncols=True, mininterval=0.1)
        
        for text_input, bio_input, label in pbar:
            
            for k in text_input:
                text_input[k] = text_input[k].to(device)
            bio_input = bio_input.to(device)
            label = label.to(device)

            if mode == "train":
                optimizer.zero_grad()

            logits = model(text_input, bio_input)
            loss = criterion(logits, label)

            if mode == "train":
                loss.backward()
                optimizer.step()

            preds = logits.argmax(dim=1)
            correct += (preds == label).sum().item()
            total += label.size(0)
            total_loss += loss.item()
            
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})

    acc = correct / total
    avg_loss = total_loss / len(loader)
    elapsed_time = time.time() - start_time

    return acc, avg_loss, elapsed_time


def evaluate_with_shuffle(model, loader, device, criterion, shuffle_bio=False, shuffle_text=False):
    """
    [ìˆ˜ì •] shuffle_text ì˜µì…˜ ì¶”ê°€
    - shuffle_bio=True : ìƒì²´ì‹ í˜¸ë¥¼ ì„ìŒ (í…ìŠ¤íŠ¸ í¸í–¥ í™•ì¸)
    - shuffle_text=True: í…ìŠ¤íŠ¸ë¥¼ ì„ìŒ (ìƒì²´ì‹ í˜¸ í¸í–¥ í™•ì¸)
    """
    model.eval()
    
    total = 0
    correct = 0
    total_loss = 0.0
    
    all_true = []
    all_pred = []

    with torch.no_grad():
        pbar = tqdm(loader, desc="TESTING", leave=False, dynamic_ncols=True, mininterval=0.1)
        
        for text_input, bio_input, label in pbar:
            
            for k in text_input:
                text_input[k] = text_input[k].to(device)
            bio_input = bio_input.to(device)
            label = label.to(device)

            # -------------------------------------------------------
            # ğŸ² Shuffling Logic
            # -------------------------------------------------------
            if shuffle_bio:
                # Bioë§Œ ì„ê¸°
                idx = torch.randperm(bio_input.size(0))
                bio_input = bio_input[idx]
            
            elif shuffle_text:
                # Textë§Œ ì„ê¸° (ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ ëª¨ë“  í…ì„œë¥¼ ê°™ì€ ì¸ë±ìŠ¤ë¡œ ì„ì–´ì•¼ í•¨)
                idx = torch.randperm(label.size(0)) # ë°°ì¹˜ ì‚¬ì´ì¦ˆë§Œí¼ ëœë¤ ì¸ë±ìŠ¤
                for k in text_input:
                    text_input[k] = text_input[k][idx]
            # -------------------------------------------------------

            logits = model(text_input, bio_input)
            loss = criterion(logits, label)
            total_loss += loss.item()

            preds = logits.argmax(dim=1)
            correct += (preds == label).sum().item()
            total += label.size(0)
            
            all_true.extend(label.cpu().tolist())
            all_pred.extend(preds.cpu().tolist())

    acc = correct / total
    avg_loss = total_loss / len(loader)
    
    return acc, avg_loss, all_true, all_pred