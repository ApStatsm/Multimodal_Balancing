import torch
import torch.nn as nn
import time
from tqdm import tqdm

def run_epoch(model, loader, optimizer, device, mode="train"):
    """
    1 Epoch ë™ì•ˆ í•™ìŠµ(Train) ë˜ëŠ” ê²€ì¦(Val)ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        acc (float): ì •í™•ë„
        avg_loss (float): í‰ê·  ì†ì‹¤ê°’
        elapsed_time (float): ê±¸ë¦° ì‹œê°„
    """
    if mode == "train":
        model.train()
    else:
        model.eval()

    total = 0
    correct = 0
    total_loss = 0.0
    
    # Loss í•¨ìˆ˜ ì •ì˜ (ì´ì§„ ë¶„ë¥˜ì§€ë§Œ CrossEntropy ì‚¬ìš© ê°€ëŠ¥)
    criterion = nn.CrossEntropyLoss()

    start_time = time.time()

    # Gradient ê³„ì‚° ì—¬ë¶€ ì„¤ì •
    with torch.set_grad_enabled(mode == "train"):
        # Tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ (leave=False: ì™„ë£Œ í›„ ì¤„ ì‚­ì œë¡œ ê¹”ë”í•˜ê²Œ)
        pbar = tqdm(loader, desc=mode.upper(), leave=False)
        
        for text_input, bio_input, label in pbar:
            
            # 1. ë°ì´í„° ì¥ì¹˜ ì´ë™
            for k in text_input:
                text_input[k] = text_input[k].to(device)
            bio_input = bio_input.to(device)
            label = label.to(device)

            # 2. ì´ˆê¸°í™”
            if mode == "train":
                optimizer.zero_grad()

            # 3. ëª¨ë¸ ì˜ˆì¸¡ (Forward)
            logits = model(text_input, bio_input)
            
            # 4. Loss ê³„ì‚°
            loss = criterion(logits, label)

            # 5. ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ê°±ì‹  (Backward)
            if mode == "train":
                loss.backward()
                optimizer.step()

            # 6. ì •í™•ë„ ê³„ì‚°
            preds = logits.argmax(dim=1)
            correct += (preds == label).sum().item()
            total += label.size(0)
            total_loss += loss.item()
            
            # Tqdm ë°”ì— í˜„ì¬ Loss í‘œì‹œ
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})

    acc = correct / total
    avg_loss = total_loss / len(loader)
    elapsed_time = time.time() - start_time

    return acc, avg_loss, elapsed_time


def evaluate_with_shuffle(model, loader, device, criterion, shuffle_bio=False):
    """
    í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜.
    shuffle_bio=Trueì¼ ê²½ìš°, ìƒì²´ì‹ í˜¸(Bio)ë¥¼ ë°°ì¹˜ ë‚´ì—ì„œ ì„ì–´ì„œ í¸í–¥ì„±ì„ í…ŒìŠ¤íŠ¸í•¨.

    Returns:
        acc (float): ì •í™•ë„
        avg_loss (float): í‰ê·  ì†ì‹¤ê°’
        all_true (list): ì‹¤ì œ ì •ë‹µ ë¦¬ìŠ¤íŠ¸ (Confusion Matrixìš©)
        all_pred (list): ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ (Confusion Matrixìš©)
    """
    model.eval()
    
    total = 0
    correct = 0
    total_loss = 0.0
    
    all_true = []
    all_pred = []

    with torch.no_grad():
        for text_input, bio_input, label in loader:
            
            # 1. ë°ì´í„° ì¥ì¹˜ ì´ë™
            for k in text_input:
                text_input[k] = text_input[k].to(device)
            bio_input = bio_input.to(device)
            label = label.to(device)

            # -------------------------------------------------------
            # ğŸ² [í•µì‹¬] Bio Signal Shuffling Logic
            # -------------------------------------------------------
            if shuffle_bio:
                # í˜„ì¬ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ëœë¤ ì¸ë±ìŠ¤ ìƒì„± (ì˜ˆ: [3, 0, 2, 1])
                idx = torch.randperm(bio_input.size(0))
                # Bio ì‹ í˜¸ ìˆœì„œë¥¼ ì„ì–´ë²„ë¦¼ (Textì™€ Labelì€ ê³ ì •)
                # ì´ë ‡ê²Œ í•˜ë©´ Textë§Œ ì •ìƒì´ê³  BioëŠ” ë…¸ì´ì¦ˆê°€ ë¨
                bio_input = bio_input[idx]
            # -------------------------------------------------------

            # 2. ëª¨ë¸ ì˜ˆì¸¡
            logits = model(text_input, bio_input)
            
            # 3. Loss ê³„ì‚°
            loss = criterion(logits, label)
            total_loss += loss.item()

            # 4. ì •í™•ë„ ë° ê²°ê³¼ ìˆ˜ì§‘
            preds = logits.argmax(dim=1)
            correct += (preds == label).sum().item()
            total += label.size(0)
            
            # ë¦¬ìŠ¤íŠ¸ì— ê²°ê³¼ ëˆ„ì  (main.pyì—ì„œ Confusion Matrix ê·¸ë¦´ ë•Œ ì‚¬ìš©)
            all_true.extend(label.cpu().tolist())
            all_pred.extend(preds.cpu().tolist())

    acc = correct / total
    avg_loss = total_loss / len(loader)
    
    return acc, avg_loss, all_true, all_pred