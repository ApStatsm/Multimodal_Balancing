from config import config
from utils import get_device
from dataset_multimodal import load_multimodal_data
from models.multimodal_e2e import MultimodalEndToEnd
# ğŸ”¥ train.pyì—ì„œ í•™ìŠµ í•¨ìˆ˜ì™€ í‰ê°€ í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from train import run_epoch, evaluate_with_shuffle 

import torch
import torch.nn as nn
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix
from torch.utils.data import DataLoader, SubsetRandomSampler
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def main():
    # ---------------------------------------------------------
    # 1. ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
    # ---------------------------------------------------------
    tokenizer = None
    from kobert_tokenizer import KoBERTTokenizer
    tokenizer = KoBERTTokenizer.from_pretrained("skt/kobert-base-v1")
    device = get_device()
    criterion = nn.CrossEntropyLoss()

    # [ì¤‘ìš”] ì´ì§„ ë¶„ë¥˜ ì„¤ì •
    config["model"]["num_classes"] = 2
    print(f"ğŸ”§ Config Update: num_classes = {config['model']['num_classes']} (Binary: Neutral vs Biased)")

    # ì „ì²´ ë°ì´í„° ë¡œë“œ (Split ì—†ì´ í•˜ë‚˜ë¡œ)
    full_loader, _, _ = load_multimodal_data(
        tokenizer=tokenizer,
        session_folder=config["paths"]["session_folder"],
        text_folder=config["paths"]["text_folder"],
        batch_size=config["training"]["batch_size"],
        max_len=config["model"]["max_len"]
    )
    full_dataset = full_loader.dataset

    # K-Foldë¥¼ ìœ„í•œ ë¼ë²¨ ì¶”ì¶œ
    all_labels = [full_dataset[i][2].item() for i in range(len(full_dataset))]
    all_labels = np.array(all_labels)

    # ---------------------------------------------------------
    # 2. 5-Fold Cross Validation ì‹œì‘
    # ---------------------------------------------------------
    n_splits = 5
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    # ì „ì²´ í´ë“œì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸ (ìµœì¢… Confusion Matrixìš©)
    global_true = []
    global_pred = []
    
    # ê²°ê³¼ ìš”ì•½ìš© ë¦¬ìŠ¤íŠ¸
    fold_results_normal_acc = []
    fold_results_shuffled_acc = []

    print(f"\n================ STARTING {n_splits}-FOLD CV ================\n")

    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(all_labels)), all_labels)):
        print(f"\n----- Fold {fold_idx+1} / {n_splits} -----")
        
        # ë°ì´í„° ë¶„í• 
        train_subsampler = SubsetRandomSampler(train_idx)
        val_subsampler = SubsetRandomSampler(val_idx) # Valì´ì Testë¡œ ì‚¬ìš©
        
        train_loader = DataLoader(full_dataset, batch_size=config["training"]["batch_size"], sampler=train_subsampler)
        test_loader = DataLoader(full_dataset, batch_size=config["training"]["batch_size"], sampler=val_subsampler)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = MultimodalEndToEnd(config).to(device)
        
        # Optimizer: Freezeëœ ë ˆì´ì–´ ì œì™¸í•˜ê³  í•™ìŠµ (Fusion Layer ìœ„ì£¼)
        optimizer = torch.optim.Adam(
            filter(lambda p: p.requires_grad, model.parameters()), 
            lr=config["training"]["learning_rate"]
        )

        # --- í•™ìŠµ ë£¨í”„ ---
        best_val_loss = float('inf')
        patience = 3
        counter = 0
        best_model_state = None
        
        for epoch in range(config["training"]["epochs"]):
            # Train
            train_acc, train_loss, train_time = run_epoch(model, train_loader, optimizer, device, mode="train")
            # Val
            val_acc, val_loss, val_time = run_epoch(model, test_loader, optimizer, device, mode="val")
            
            print(f"Ep {epoch+1:02d} | Train: {train_acc:.4f} ({train_loss:.4f}) | Val: {val_acc:.4f} ({val_loss:.4f})")
            
            # Early Stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_model_state = model.state_dict()
                counter = 0
            else:
                counter += 1
                if counter >= patience:
                    print(f"   >> ğŸ›‘ Early Stopping (Best Val Loss: {best_val_loss:.4f})")
                    break
        
        # --- í…ŒìŠ¤íŠ¸ & í‰ê°€ ---
        if best_model_state:
            model.load_state_dict(best_model_state)
            
        # 1. Normal Test (ì •ìƒ)
        norm_acc, norm_loss, fold_true, fold_pred = evaluate_with_shuffle(
            model, test_loader, device, criterion, shuffle_bio=False
        )
        # 2. Shuffled Test (Bio ì„ê¸° - í¸í–¥ ë¶„ì„ìš©)
        shuf_acc, shuf_loss, _, _ = evaluate_with_shuffle(
            model, test_loader, device, criterion, shuffle_bio=True
        )
        
        fold_results_normal_acc.append(norm_acc)
        fold_results_shuffled_acc.append(shuf_acc)
        
        # Confusion Matrixë¥¼ ìœ„í•´ ì˜ˆì¸¡ê°’ ëˆ„ì 
        global_true.extend(fold_true)
        global_pred.extend(fold_pred)

        print(f"   ğŸ‘‰ [Result] Normal Acc: {norm_acc:.4f} | Shuffled Acc: {shuf_acc:.4f}")
        print(f"   âš ï¸  Gap: {norm_acc - shuf_acc:.4f}")

    # ---------------------------------------------------------
    # 3. ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì‹œê°í™”
    # ---------------------------------------------------------
    print("\n================ FINAL SUMMARY ================\n")
    
    avg_norm = np.mean(fold_results_normal_acc)
    avg_shuf = np.mean(fold_results_shuffled_acc)
    
    print(f"1ï¸âƒ£  Avg Normal Accuracy   : {avg_norm:.4f}")
    print(f"2ï¸âƒ£  Avg Shuffled Accuracy : {avg_shuf:.4f}")
    print(f"ğŸ“‰ Performance Drop (Gap)  : {avg_norm - avg_shuf:.4f}")
    
    if (avg_norm - avg_shuf) < 0.05:
        print("ğŸš¨ [í•´ì„] ì„±ëŠ¥ ì°¨ì´ê°€ ê±°ì˜ ì—†ìŒ -> í…ìŠ¤íŠ¸(Text) í¸í–¥ ì˜ì‹¬")
    else:
        print("âœ… [í•´ì„] ì„±ëŠ¥ í•˜ë½ ë°œìƒ -> ìƒì²´ì‹ í˜¸(Bio) ìœ ì˜ë¯¸í•˜ê²Œ ì‚¬ìš© ì¤‘")

    # ---------------------------------------------------------
    # 4. Confusion Matrix ì €ì¥ (ìš”ì²­í•˜ì‹  ìŠ¤íƒ€ì¼ ì ìš©)
    # ---------------------------------------------------------
    print("\nGenerating Confusion Matrix...")
    
    cm = confusion_matrix(global_true, global_pred)
    # ì´ì§„ ë¶„ë¥˜ ë¼ë²¨
    labels = ["Neutral", "Biased"] 

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(f"Confusion Matrix (Accumulated over {n_splits}-Folds)")
    plt.tight_layout()
    plt.savefig("confusion_matrix.png")
    plt.show()

    print(f"ğŸ’¾ Confusion Matrix saved to 'confusion_matrix.png'")
    print("\n================ DONE =================\n")

if __name__ == "__main__":
    main()