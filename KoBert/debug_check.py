import torch
from kobert_tokenizer import KoBERTTokenizer
from dataset import load_data_from_folders
from utils import get_device

def debug_data():
    # ==========================================
    # â— ë³¸ì¸ì˜ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”
    # ==========================================
    csv_path = r"/Users/apstat/Desktop/02_á„‹á…§á†«á„€á…®/Multimodal_Balancing/19data"
    text_folder = r"/Users/apstat/Desktop/02_á„‹á…§á†«á„€á…®/Multimodal_Balancing/KEMDy19_v1_3/wav"
    # ==========================================

    tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')

    print("ğŸ” ë°ì´í„° ë¡œë”© ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    train_loader, _ = load_data_from_folders(
        tokenizer=tokenizer,
        csv_path=csv_path,
        text_folder=text_folder,
        batch_size=16
    )

    print("\n" + "="*50)
    print("ğŸ“¢ [ë°ì´í„° X-Ray ê²€ì‚¬] ëª¨ë¸ì´ ì‹¤ì œë¡œ ë³´ëŠ” í…ìŠ¤íŠ¸")
    print("="*50)

    # ë°°ì¹˜ë¥¼ í•˜ë‚˜ ë½‘ì•„ì„œ ë‚´ìš©ë¬¼ í™•ì¸
    for batch in train_loader:
        texts = batch['text']
        labels = batch['label']
        
        # 5ê°œë§Œ ì¶œë ¥
        for i in range(5):
            print(f"\n[Sample {i+1}]")
            print(f"ğŸ‘‰ Label (ì •ë‹µ): {labels[i].item()}") # 0~4 ìˆ«ì
            print(f"ğŸ‘‰ Text  (ì…ë ¥): {texts[i]}")
        
        break  # í•˜ë‚˜ë§Œ ë³´ê³  ì¢…ë£Œ

if __name__ == "__main__":
    debug_data()