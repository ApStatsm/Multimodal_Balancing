{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6c8d42-bdf6-4dd8-9c59-b6d02df4e55e",
   "metadata": {},
   "source": [
    "## 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "959597d4-14a0-4bbc-bdb3-9e8e64c28ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 40개의 파일을 찾았습니다:\n",
      "\n",
      "데이터 통합 완료. 총 301008개의 행이 로드되었습니다.\n",
      "7개 감정 클래스 확인: ['neutral' 'happy' 'angry' 'disgust' 'sad' 'surprise' 'fear']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os  \n",
    "\n",
    "base_path = '/Users/apstat/Desktop/연구/멀티모달 밸런싱/데이터'\n",
    "search_pattern = os.path.join(base_path, \"Sess*.csv\")\n",
    "file_paths = glob.glob(search_pattern)\n",
    "\n",
    "print(f\"총 {len(file_paths)}개의 파일을 찾았습니다:\")\n",
    "# print(file_paths)\n",
    "\n",
    "all_dfs = []\n",
    "for path in file_paths:\n",
    "    try:\n",
    "        all_dfs.append(pd.read_csv(path))\n",
    "    except Exception as e:\n",
    "        print(f\"파일을 읽는 중 오류 발생: {path}, 오류: {e}\")\n",
    "\n",
    "\n",
    "if all_dfs:\n",
    "    df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\n데이터 통합 완료. 총 {len(df_all)}개의 행이 로드되었습니다.\")\n",
    "    print(f\"7개 감정 클래스 확인: {df_all['Emotion'].unique()}\")\n",
    "else:\n",
    "    print(\"\\n[오류] CSV 파일을 찾지 못했거나 읽을 수 없습니다. 경로와 파일 이름을 확인하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2efe0c1a-ea3d-4348-8ee4-a2a2e130777c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 7개의 감정 클래스를 찾았습니다: ['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1a. 특징 및 레이블 정의\n",
    "# 시계열 특징(EDA, TEMP)과 정적 특징(Valence, Arousal)을 모두 사용\n",
    "features = ['EDA', 'TEMP', 'Valence', 'Arousal']\n",
    "target = 'Emotion'\n",
    "\n",
    "# 1b. 특징 스케일링 (StandardScaler)\n",
    "# (중요!) 10개 파일의 모든 행에 대해 스케일러를 'fit'\n",
    "scaler = StandardScaler()\n",
    "df_all[features] = scaler.fit_transform(df_all[features])\n",
    "\n",
    "# 1c. 레이블 인코딩\n",
    "# 'happy' -> 2, 'neutral' -> 4 등 숫자로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "df_all[target] = label_encoder.fit_transform(df_all[target])\n",
    "\n",
    "# 7개 감정 클래스 확인\n",
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"총 {n_classes}개의 감정 클래스를 찾았습니다: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6609c1f4-5427-4ce2-8a8c-97d0d81b7dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment_ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>EDA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess21_script01_User042F_001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.056340</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>-0.324641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess21_script01_User042F_001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.057462</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>-0.324641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess21_script01_User042F_001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.061050</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>-0.324641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess21_script01_User042F_001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.061722</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>-0.324641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess21_script01_User042F_001</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.061050</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>-0.324641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Segment_ID  Time       EDA      TEMP  Emotion  Valence  \\\n",
       "0  Sess21_script01_User042F_001  0.25 -0.056340  0.172719        4  0.94888   \n",
       "1  Sess21_script01_User042F_001  0.50 -0.057462  0.172719        4  0.94888   \n",
       "2  Sess21_script01_User042F_001  0.75 -0.061050  0.172719        4  0.94888   \n",
       "3  Sess21_script01_User042F_001  1.00 -0.061722  0.172719        4  0.94888   \n",
       "4  Sess21_script01_User042F_001  1.25 -0.061050  0.172719        4  0.94888   \n",
       "\n",
       "    Arousal  \n",
       "0 -0.324641  \n",
       "1 -0.324641  \n",
       "2 -0.324641  \n",
       "3 -0.324641  \n",
       "4 -0.324641  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d975c2bb-c17d-4723-950e-f952c337a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 시퀀스 생성 (Padding) ---\n",
      "가장 긴 시퀀스의 길이 (max_len): 141\n",
      "최종 X 데이터 형태 (샘플, 최대길이, 특징): (12763, 141, 4)\n",
      "최종 y 데이터 형태 (샘플, 클래스 수): (12763, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"\\n--- 2. 시퀀스 생성 (Padding) ---\")\n",
    "\n",
    "# 2a. Segment_ID별로 묶기\n",
    "grouped = df_all.groupby('Segment_ID')\n",
    "\n",
    "# 2b. 각 Segment_ID의 (길이, 4개 특징) 배열을 리스트에 저장\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    # 4개 특징의 시퀀스 (numpy array)\n",
    "    X_sequences.append(group[features].values)\n",
    "    # 해당 ID의 첫 번째 레이블 (어차피 다 같음)\n",
    "    y_labels.append(group[target].iloc[0])\n",
    "\n",
    "# 2c. 가장 긴 시퀀스의 길이(TimeSteps) 찾기\n",
    "max_len = max(len(seq) for seq in X_sequences)\n",
    "print(f\"가장 긴 시퀀스의 길이 (max_len): {max_len}\")\n",
    "\n",
    "# 2d. 패딩(Padding) 수행\n",
    "# 'post': 시퀀스 뒤쪽에 0.0을 채움\n",
    "X_padded = pad_sequences(\n",
    "    X_sequences, \n",
    "    maxlen=max_len, \n",
    "    padding='post', \n",
    "    dtype='float32', \n",
    "    value=0.0 # 패딩 값은 0.0\n",
    ")\n",
    "\n",
    "# 2e. 레이블을 numpy 배열로 변환 및 원-핫 인코딩\n",
    "y_array = np.array(y_labels)\n",
    "y_categorical = to_categorical(y_array, num_classes=n_classes)\n",
    "\n",
    "print(f\"최종 X 데이터 형태 (샘플, 최대길이, 특징): {X_padded.shape}\")\n",
    "print(f\"최종 y 데이터 형태 (샘플, 클래스 수): {y_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b63aaaa4-373c-4178-a417-96a4202be296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. 데이터 분리 (6:2:2) ---\n",
      "Train: (7657, 141, 4), (7657, 7)\n",
      "Validation: (2553, 141, 4), (2553, 7)\n",
      "Test: (2553, 141, 4), (2553, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n--- 3. 데이터 분리 (6:2:2) ---\")\n",
    "\n",
    "# X = X_padded, y = y_categorical\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_padded, y_categorical,\n",
    "    test_size=0.4, \n",
    "    random_state=42, \n",
    "    stratify=y_array # (중요!) 원-핫 인코딩 전의 y_array로 비율 맞춤\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5, \n",
    "    random_state=42, \n",
    "    stratify=y_temp.argmax(axis=1) # (임시 y로 비율 맞춤)\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75111817-361d-4cb8-be7e-dab76921f05a",
   "metadata": {},
   "source": [
    "## simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae9fb8c9-559a-4e66-b1ad-be3c898d3b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. 기본 RNN (SimpleRNN) 모델 구축 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">141</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_9 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m141\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_6 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,727</span> (26.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,727\u001b[0m (26.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,727</span> (26.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,727\u001b[0m (26.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Masking\n",
    "from tensorflow.keras.layers import SimpleRNN  # [수정] LSTM 대신 SimpleRNN을 import\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(\"\\n--- 4. 기본 RNN (SimpleRNN) 모델 구축 ---\")\n",
    "\n",
    "# 4a. 모델 파라미터 정의\n",
    "n_features = 4  # (EDA, TEMP, Valence, Arousal)\n",
    "# max_len은 2단계에서 계산됨\n",
    "\n",
    "# 4b. 모델 생성\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# Input Layer 및 Masking Layer (동일)\n",
    "rnn_model.add(Input(shape=(max_len, n_features)))\n",
    "rnn_model.add(Masking(mask_value=0.0))\n",
    "\n",
    "# [수정] LSTM 레이어 대신 SimpleRNN 레이어 사용\n",
    "# (SimpleRNN은 vanishing gradient 문제로 LSTM보다 성능이 낮을 수 있음)\n",
    "rnn_model.add(SimpleRNN(units=64))\n",
    "\n",
    "# (선택) 과적합 방지 (동일)\n",
    "rnn_model.add(Dropout(0.3))\n",
    "rnn_model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Output Layer (동일)\n",
    "rnn_model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# 4c. 모델 컴파일 (동일)\n",
    "rnn_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4657bda-f083-4b86-80b3-d6cf8d0a3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. 모델 학습 및 평가 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.5063 - val_accuracy: 0.9080 - val_loss: 0.3349\n",
      "Epoch 2/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9051 - loss: 0.3411 - val_accuracy: 0.9064 - val_loss: 0.3224\n",
      "Epoch 3/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.3230 - val_accuracy: 0.9001 - val_loss: 0.3474\n",
      "Epoch 4/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9105 - loss: 0.3201 - val_accuracy: 0.9146 - val_loss: 0.3082\n",
      "Epoch 5/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.3125 - val_accuracy: 0.9130 - val_loss: 0.3036\n",
      "Epoch 6/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.3110 - val_accuracy: 0.9138 - val_loss: 0.3066\n",
      "Epoch 7/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.3080 - val_accuracy: 0.9091 - val_loss: 0.3093\n",
      "Epoch 8/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.3044 - val_accuracy: 0.9142 - val_loss: 0.2993\n",
      "Epoch 9/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9143 - loss: 0.3022 - val_accuracy: 0.9150 - val_loss: 0.3000\n",
      "Epoch 10/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9120 - loss: 0.3099 - val_accuracy: 0.9127 - val_loss: 0.3040\n",
      "Epoch 11/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9117 - loss: 0.3069 - val_accuracy: 0.9119 - val_loss: 0.3090\n",
      "Epoch 12/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.3075 - val_accuracy: 0.9150 - val_loss: 0.2973\n",
      "Epoch 13/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9083 - loss: 0.3292 - val_accuracy: 0.9111 - val_loss: 0.3064\n",
      "Epoch 14/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.3172 - val_accuracy: 0.9127 - val_loss: 0.3026\n",
      "Epoch 15/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9065 - loss: 0.3127 - val_accuracy: 0.9123 - val_loss: 0.3087\n",
      "Epoch 16/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.3101 - val_accuracy: 0.9142 - val_loss: 0.2983\n",
      "Epoch 17/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.3045 - val_accuracy: 0.9158 - val_loss: 0.2976\n",
      "\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- 5. 모델 학습 및 평가 ---\")\n",
    "\n",
    "# 5a. 조기 종료(EarlyStopping) 설정\n",
    "# Validation loss가 5번 연속 개선되지 않으면 학습 중지\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True # 가장 좋았던 가중치 복원\n",
    ")\n",
    "\n",
    "# 5b. 모델 학습\n",
    "history = rnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50, # (최대 50번, 그 전에 조기 종료될 수 있음)\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopper]\n",
    ")\n",
    "\n",
    "print(\"\\n학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8eaf2fcf-9d47-43d2-b39d-28b7217577b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 최종 평가 (Test Set) ---\n",
      "Test Loss: 0.2925\n",
      "Test Accuracy: 0.9146\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Final Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry     1.0000    0.1724    0.2941        29\n",
      "     disgust     0.0000    0.0000    0.0000        12\n",
      "        fear     0.0000    0.0000    0.0000         8\n",
      "       happy     0.7868    0.6596    0.7176       235\n",
      "     neutral     0.9251    0.9824    0.9529      2214\n",
      "         sad     0.0000    0.0000    0.0000        24\n",
      "    surprise     0.0000    0.0000    0.0000        31\n",
      "\n",
      "    accuracy                         0.9146      2553\n",
      "   macro avg     0.3874    0.2592    0.2807      2553\n",
      "weighted avg     0.8861    0.9146    0.8958      2553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5c. 최종 평가 (Test Set)\n",
    "print(\"\\n--- 최종 평가 (Test Set) ---\")\n",
    "test_loss, test_accuracy = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 5d. 분류 리포트 (Classification Report)\n",
    "y_pred_probs = rnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1) # (확률 -> 클래스 0~6)\n",
    "y_test_classes = np.argmax(y_test, axis=1)     # (원-핫 -> 클래스 0~6)\n",
    "\n",
    "# 레이블 인코더로 원래 감정 이름 가져오기\n",
    "target_names = label_encoder.classes_\n",
    "print(\"\\nFinal Classification Report (Test Set):\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478a669-4788-4c75-a123-13ec284ba092",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc238142-e015-4550-ad0e-c1351c325e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. LSTM 모델 구축 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">141</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_10 (\u001b[38;5;33mMasking\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m141\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m17,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,975</span> (78.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,975\u001b[0m (78.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,975</span> (78.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,975\u001b[0m (78.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(\"\\n--- 4. LSTM 모델 구축 ---\")\n",
    "\n",
    "# 4a. 모델 파라미터 정의\n",
    "n_features = 4  # (EDA, TEMP, Valence, Arousal)\n",
    "# max_len은 2단계에서 계산됨\n",
    "\n",
    "# 4b. 모델 생성\n",
    "lstm = Sequential()\n",
    "\n",
    "# (중요!) Input Layer: 입력 형태 정의\n",
    "# (None, n_features)는 (max_len, n_features)와 동일\n",
    "lstm.add(Input(shape=(max_len, n_features)))\n",
    "\n",
    "# (중요!) Masking Layer: 패딩 값 0.0을 무시하도록 설정\n",
    "lstm.add(Masking(mask_value=0.0))\n",
    "\n",
    "# LSTM Layer: 64개 유닛. \n",
    "# return_sequences=False (기본값): 마지막 타임스텝의 출력만 전달\n",
    "lstm.add(LSTM(units=64))\n",
    "\n",
    "# (선택) 과적합 방지\n",
    "lstm.add(Dropout(0.3))\n",
    "lstm.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Output Layer: 7개 감정 클래스로 분류\n",
    "lstm.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# 4c. 모델 컴파일\n",
    "lstm.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', # (원-핫 인코딩이므로)\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28645f2d-e5f2-47ae-a5bb-8fc37cada4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. 모델 학습 및 평가 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8643 - loss: 0.5561 - val_accuracy: 0.9119 - val_loss: 0.3303\n",
      "Epoch 2/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8960 - loss: 0.3434 - val_accuracy: 0.9099 - val_loss: 0.3190\n",
      "Epoch 3/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9030 - loss: 0.3262 - val_accuracy: 0.9142 - val_loss: 0.3094\n",
      "Epoch 4/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9116 - loss: 0.3106 - val_accuracy: 0.9150 - val_loss: 0.2994\n",
      "Epoch 5/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9113 - loss: 0.3063 - val_accuracy: 0.9134 - val_loss: 0.2953\n",
      "Epoch 6/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9134 - loss: 0.3006 - val_accuracy: 0.9115 - val_loss: 0.3044\n",
      "Epoch 7/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9146 - loss: 0.3015 - val_accuracy: 0.9138 - val_loss: 0.2952\n",
      "Epoch 8/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9122 - loss: 0.3017 - val_accuracy: 0.9115 - val_loss: 0.2986\n",
      "Epoch 9/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9132 - loss: 0.2978 - val_accuracy: 0.9107 - val_loss: 0.3031\n",
      "Epoch 10/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9135 - loss: 0.2942 - val_accuracy: 0.9138 - val_loss: 0.2931\n",
      "Epoch 11/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9162 - loss: 0.2916 - val_accuracy: 0.9130 - val_loss: 0.2992\n",
      "Epoch 12/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9146 - loss: 0.2927 - val_accuracy: 0.9138 - val_loss: 0.2946\n",
      "Epoch 13/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9128 - loss: 0.2886 - val_accuracy: 0.9134 - val_loss: 0.3014\n",
      "Epoch 14/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9120 - loss: 0.2886 - val_accuracy: 0.9119 - val_loss: 0.3005\n",
      "Epoch 15/50\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9156 - loss: 0.2849 - val_accuracy: 0.9150 - val_loss: 0.2971\n",
      "\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- 5. 모델 학습 및 평가 ---\")\n",
    "\n",
    "# 5a. 조기 종료(EarlyStopping) 설정\n",
    "# Validation loss가 5번 연속 개선되지 않으면 학습 중지\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True # 가장 좋았던 가중치 복원\n",
    ")\n",
    "\n",
    "# 5b. 모델 학습\n",
    "history = lstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50, # (최대 50번, 그 전에 조기 종료될 수 있음)\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopper]\n",
    ")\n",
    "\n",
    "print(\"\\n학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e714d8cd-ea97-422b-9ae6-9080f6c93397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 최종 평가 (Test Set) ---\n",
      "Test Loss: 0.2927\n",
      "Test Accuracy: 0.9142\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "Final Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry     0.6250    0.1724    0.2703        29\n",
      "     disgust     0.0000    0.0000    0.0000        12\n",
      "        fear     0.0000    0.0000    0.0000         8\n",
      "       happy     0.7979    0.6553    0.7196       235\n",
      "     neutral     0.9247    0.9824    0.9527      2214\n",
      "         sad     0.0000    0.0000    0.0000        24\n",
      "    surprise     0.0000    0.0000    0.0000        31\n",
      "\n",
      "    accuracy                         0.9142      2553\n",
      "   macro avg     0.3354    0.2586    0.2775      2553\n",
      "weighted avg     0.8825    0.9142    0.8955      2553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5c. 최종 평가 (Test Set)\n",
    "print(\"\\n--- 최종 평가 (Test Set) ---\")\n",
    "test_loss, test_accuracy = lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 5d. 분류 리포트 (Classification Report)\n",
    "y_pred_probs = lstm.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1) # (확률 -> 클래스 0~6)\n",
    "y_test_classes = np.argmax(y_test, axis=1)     # (원-핫 -> 클래스 0~6)\n",
    "\n",
    "# 레이블 인코더로 원래 감정 이름 가져오기\n",
    "target_names = label_encoder.classes_\n",
    "print(\"\\nFinal Classification Report (Test Set):\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c521be-1e09-4a12-aaa5-6e87cbf921e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f42bd-1e8b-4338-ac2c-523edffd42c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
