import os
import torch
import pandas as pd
import chardet
from torch.utils.data import Dataset
from sklearn.model_selection import train_test_split
import numpy as np # ğŸ”¥ numpy ì¶”ê°€

class MultimodalDataset(Dataset):
    # ğŸ”¥ weights íŒŒë¼ë¯¸í„° ì¶”ê°€ ë° ì €ì¥
    def __init__(self, df, text_folder, tokenizer, max_len=128, weights=None):
        self.df = df.reset_index(drop=True)
        self.text_folder = text_folder
        self.tokenizer = tokenizer
        self.max_len = max_len

        # ğŸ”¥ ê°€ì¤‘ì¹˜ ì„¤ì •: ì œê³µëœ ê°€ì¤‘ì¹˜ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ 1ë¡œ ì„¤ì •
        if weights is None:
            self.weights = np.ones(len(self.df), dtype=np.float32)
        else:
            if len(weights) != len(self.df):
                raise ValueError("Weights length must match DataFrame length.")
            self.weights = np.array(weights, dtype=np.float32)

        self.texts = []
        self.bio_features = []
        self.labels = []
        
        # ... (ì´í•˜ ê¸°ì¡´ __init__ ë¡œì§ ìœ ì§€) ...
        for _, row in self.df.iterrows():
            seg_id = str(row["Segment_ID"]).strip()
            
            # ì´ì§„ ë¶„ë¥˜: neutral(0) vs others(1)
            raw_emotion = row["Emotion"].lower()
            # config.py ê¸°ì¤€ìœ¼ë¡œ 2í´ë˜ìŠ¤ ì´ë¯€ë¡œ 0 ë˜ëŠ” 1
            label = 0 if raw_emotion == "neutral" else 1

            bio_vals = [
                float(row["EDA"]),
                float(row["TEMP"]),
                float(row["Valence"]),
                float(row["Arousal"])
            ]
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸° (ê¸°ì¡´ ë¡œì§)
            txt_path = None
            for root, _, files in os.walk(self.text_folder):
                if f"{seg_id}.txt" in files:
                    txt_path = os.path.join(root, f"{seg_id}.txt")
                    break

            text = ""
            if txt_path:
                try:
                    with open(txt_path, "rb") as f:
                        raw = f.read()
                        enc = chardet.detect(raw)["encoding"] or "utf-8"
                    with open(txt_path, "r", encoding=enc) as f:
                        text = f.read().strip()
                except Exception as e:
                    print(f"Error reading {txt_path}: {e}")
                    text = "[NO_TEXT]"
            else:
                 text = "[NO_TEXT]"

            self.texts.append(text)
            self.bio_features.append(bio_vals)
            self.labels.append(label)


    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        text = self.texts[idx]
        bio_input = torch.tensor(self.bio_features[idx], dtype=torch.float)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        # ğŸ”¥ ê°€ì¤‘ì¹˜ ë°˜í™˜
        weight = torch.tensor(self.weights[idx], dtype=torch.float)
        
        text_input = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            padding="max_length",
            truncation=True,
            return_tensors='pt',
            return_token_type_ids=True,
            return_attention_mask=True
        )
        
        # í…ì„œ ì°¨ì› ì œê±° (Batch=1)
        text_input = {k: v.squeeze(0) for k, v in text_input.items()}
        
        # ğŸ”¥ weight ë°˜í™˜ê°’ì— ì¶”ê°€
        return text_input, bio_input, label, weight 

# load_data_frames í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€
def load_data_frames(session_folder):
    """
    CSVë¥¼ ì½ê³  ì „ì²˜ë¦¬í•œ ë’¤, Train/Test DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    (Fear, Disgust ì œì™¸ ë¡œì§ ë° 8:2 ë¶„í•  ë¡œì§)
    """
    # (ìƒëµ: ê¸°ì¡´ load_data_frames í•¨ìˆ˜ ë‚´ìš©)
    csv_files = [f for f in os.listdir(session_folder) if f.endswith(".csv")]
    dfs = []
    for fname in csv_files:
        path = os.path.join(session_folder, fname)
        df = pd.read_csv(path)
        dfs.append(df)
    
    df = pd.concat(dfs, ignore_index=True)
    
    # ì„¸ì…˜ë³„ ì§‘ê³„
    grouped = (
        df.groupby("Segment_ID")
        .agg({
            "EDA": "mean", "TEMP": "mean",
            "Valence": "mean", "Arousal": "mean",
            "Emotion": lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0],
        })
        .reset_index()
    )

    # Fear, Disgust ì œê±°
    exclude_emotions = ['fear', 'disgust']
    grouped = grouped[~grouped['Emotion'].str.lower().isin(exclude_emotions)]
    
    print(f"Dataset Filtered: Removed Fear/Disgust. Total Samples: {len(grouped)}")

    # [ìˆ˜ì • í›„] ğŸ”¥ 8:2 ë¶„í•  ë¡œì§ (Train: 80%, Test: 20%)
    train_df, test_df = train_test_split(
        grouped, 
        test_size=0.2, 
        random_state=42, 
        stratify=grouped['Emotion']
    )

    print(f"Data Split: Train={len(train_df)}, Test={len(test_df)}")
    
    # ğŸ”¥ ë°˜í™˜ê°’ì—ì„œ val_df ì œê±°
    return train_df, test_df