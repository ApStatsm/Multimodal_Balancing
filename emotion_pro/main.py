from config import config
from utils import get_device
from dataset_multimodal import load_data_frames, MultimodalDataset
from models.multimodal_e2e import MultimodalEndToEnd
# ğŸ”¥ train.pyì—ì„œ run_epoch, test_multimodal, WeightedCrossEntropyLoss ì„í¬íŠ¸
from train import run_epoch, test_multimodal, WeightedCrossEntropyLoss 
import os
import torch
from torch.utils.data import DataLoader
from kobert_tokenizer import KoBERTTokenizer

# ğŸ“Š ì‹œê°í™” ë° í‰ê°€ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import time

# =============================================================================
# ğŸ”¥ ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜ (STAGE 2)
# =============================================================================
def calculate_weights_bio_only(preds_A, preds_B, labels):
    """
    Bio-Only ëª¨ë¸(B)ì˜ ì˜¤ë¶„ë¥˜ ì§‘í•©(M)ì— T ê¸°ë°˜ì˜ ì ì‘ì  ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
    Args:
        preds_A (np.array): ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ Aì˜ ì˜ˆì¸¡ê°’ (Train Set ê¸°ì¤€)
        preds_B (np.array): Bio-Only ëª¨ë¸ Bì˜ ì˜ˆì¸¡ê°’ (Train Set ê¸°ì¤€)
        labels (np.array): ì‹¤ì œ ë ˆì´ë¸”
    Returns:
        list: ìƒ˜í”Œë³„ ê°€ì¤‘ì¹˜ ë¦¬ìŠ¤íŠ¸
    """
    # 1. F1-score ê³„ì‚°
    f1_A = f1_score(labels, preds_A, average='macro', zero_division=0)
    f1_B = f1_score(labels, preds_B, average='macro', zero_division=0)
    
    # 2. ë©€í‹°ëª¨ë‹¬ ì´ë“ T ê³„ì‚° (Bias Measurement)
    T = f1_A - f1_B
    
    # 3. ì ì‘ì  ê°€ì¤‘ì¹˜ ê³„ìˆ˜ W_Adaptive ì‚°ì¶œ
    T_min = 0.001       # Tì˜ ìµœì†Œ ì•ˆì •í™” ê°’ (0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€)
    epsilon = 1e-6      # ì•ˆì •í™” ìƒìˆ˜
    gamma = 1.0         # ê°€ì¤‘ì¹˜ íŠœë‹ íŒŒë¼ë¯¸í„° (ì¡°ì ˆ ê°€ëŠ¥)

    T_Stabilized = max(T, T_min) + epsilon
    
    # Tê°€ ì‘ì„ìˆ˜ë¡ W_AdaptiveëŠ” ì»¤ì§„ë‹¤. (Bio-Only ì„±ëŠ¥ê³¼ A ì„±ëŠ¥ ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ Text ê¸°ì—¬ë¥¼ ê°•ì œ)
    W_Adaptive = gamma * np.log(1 + 1 / T_Stabilized)
    
    # 4. M ì§‘í•© (Bio-Only ëª¨ë¸ì´ í‹€ë¦° ìƒ˜í”Œ) ì‹ë³„
    # B ëª¨ë¸ì´ í‹€ë ¸ì„ ë•Œì˜ ì¸ë±ìŠ¤
    M_indices = np.where(preds_B != labels)[0] 
    
    # 5. ê°€ì¤‘ì¹˜ í• ë‹¹
    weights = np.ones(len(labels), dtype=np.float32)
    weights[M_indices] = 1.0 + W_Adaptive
    
    print(f"  F1_A (Multimodal): {f1_A:.4f}, F1_B (Bio-Only): {f1_B:.4f}")
    print(f"  T (Multimodal Gain): {T:.4f}, W_Adaptive Max Coef: {W_Adaptive:.4f}")
    print(f"  M Set Size: {len(M_indices)} / {len(labels)} ({len(M_indices)/len(labels)*100:.2f}%)")
    print(f"  Max Sample Weight: {1.0 + W_Adaptive:.4f}\n")
    
    return weights.tolist() 


def save_plots_and_report(scenario_name, labels, preds, probs):
    """
    ê²°ê³¼ ì¶œë ¥ ë° ì‹œê°í™” ì €ì¥ í•¨ìˆ˜ (emotion/result í´ë”ì— ì €ì¥)
    """
    output_dir = os.path.join("emotion", "result")
    os.makedirs(output_dir, exist_ok=True)  
    
    # 1. Classification Report
    target_names = ["Neutral", "Surprise", "Angry", "Sad", "Happy"]
    print(f"\n>> Classification Report ({scenario_name}):")
    print(classification_report(labels, preds, target_names=target_names, digits=4))

    # 2. Confusion Matrix
    cm = confusion_matrix(labels, preds)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=target_names, yticklabels=target_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'Confusion Matrix - {scenario_name}')
    plt.tight_layout()
    save_path_cm = os.path.join(output_dir, f'{scenario_name}_confusion_matrix.png')
    plt.savefig(save_path_cm)
    plt.close()
    print(f"   [Save] Confusion Matrix: {save_path_cm}")


def main():
    # 0. ì„¤ì • ë¡œë“œ ë° ì¥ì¹˜/í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
    device = get_device()
    tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')
    
    # 1. ë°ì´í„° ë¡œë“œ (ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ë¡œë“œ)
    train_df, test_df = load_data_frames(config["paths"]["session_folder"])
    
    # ================= ğŸš€ STAGE 1: ì´ˆê¸° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ A í•™ìŠµ (No Weights) =================
    print("\n\n=============== ğŸš€ STAGE 1: Initial Multimodal Training (Model A) ===============")
    
    # 1ì°¨ í•™ìŠµìš© ë°ì´í„°ì…‹ (ê°€ì¤‘ì¹˜=None, ëª¨ë‘ 1)
    train_ds_stage1 = MultimodalDataset(train_df, config["paths"]["text_folder"], tokenizer)
    train_loader = DataLoader(train_ds_stage1, batch_size=config["training"]["batch_size"], shuffle=True)
    
    # Test ë¡œë” (ê°€ì¤‘ì¹˜ ë¯¸ì‚¬ìš©)
    test_ds = MultimodalDataset(test_df, config["paths"]["text_folder"], tokenizer)
    test_loader = DataLoader(test_ds, batch_size=config["training"]["batch_size"], shuffle=False)

    print(f"Data Split: Train/Test Samples: {len(train_df)}/{len(test_df)}")

    # ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” (Model A)
    model_A = MultimodalEndToEnd(config).to(device)
    optimizer_A = torch.optim.AdamW(model_A.parameters(), lr=config["training"]["learning_rate"])
    
    for epoch in range(config["training"]["epochs"]):
        t_loss, t_acc = run_epoch(model_A, train_loader, optimizer_A, device, "train")
        v_acc, v_loss, _, _, _ = test_multimodal(model_A, test_loader, device, shuffle_mode="none")
        print(f"Ep {epoch+1:02d} (A) | Train Acc: {t_acc:.3f}, Loss: {t_loss:.4f} | Test Acc: {v_acc:.3f}")
        
    
    # ================= âš–ï¸ STAGE 2: ê°€ì¤‘ì¹˜ ê³„ì‚° ë° M ì‹ë³„ (Bio-Only Baseline) =================
    print("\n\n=============== âš–ï¸ STAGE 2: Adaptive Weight Calculation (Bio-Only Baseline) ===============")

    # 1. ê°€ì¤‘ì¹˜ ê³„ì‚°ì„ ìœ„í•´ ì…”í”Œë§ë˜ì§€ ì•Šì€ Train Loader ì‚¬ìš©
    train_loader_unshuffled = DataLoader(train_ds_stage1, 
                                         batch_size=config["training"]["batch_size"], 
                                         shuffle=False)
    
    # 2. ë©€í‹°ëª¨ë‹¬ F1_A ê³„ì‚° (shuffle_mode="none")
    print("  Testing Model A (Multimodal) on Train Set...")
    _, _, labels_A, preds_A, _ = test_multimodal(model_A, train_loader_unshuffled, device, shuffle_mode="none")

    # 3. Bio-Only F1_B ê³„ì‚° (shuffle_mode="text_zeroout")
    print("  Testing Model A (Bio-Only) on Train Set...")
    # ğŸ”¥ í…ìŠ¤íŠ¸ ì¸í’‹ì„ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ Bio ëª¨ë‹¬ë¦¬í‹°ë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ Bì˜ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
    _, _, labels_B, preds_B, _ = test_multimodal(model_A, train_loader_unshuffled, device, shuffle_mode="text_zeroout") 

    # 4. ê°€ì¤‘ì¹˜ w_i ê³„ì‚° ë° ì¶”ì¶œ
    new_weights = calculate_weights_bio_only(np.array(preds_A), np.array(preds_B), np.array(labels_A))


    # ================= ğŸ”„ STAGE 3: ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ A' ì¬í•™ìŠµ =================
    print("\n\n=============== ğŸ”„ STAGE 3: Weighted Re-Training (Model A') ===============")

    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” (ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘í•˜ê±°ë‚˜, A ëª¨ë¸ì„ ë³µì‚¬í•˜ì—¬ ì‹œì‘)
    model_A_prime = MultimodalEndToEnd(config).to(device)
    # A ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ì„œ ì‹œì‘
    model_A_prime.load_state_dict(model_A.state_dict()) 
    optimizer_A_prime = torch.optim.AdamW(model_A_prime.parameters(), lr=config["training"]["learning_rate"])
    
    # 1. ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ìƒˆë¡œìš´ ë°ì´í„°ì…‹/ë¡œë” ìƒì„±
    train_ds_stage2 = MultimodalDataset(train_df, config["paths"]["text_folder"], tokenizer, weights=new_weights)
    train_loader_stage2 = DataLoader(train_ds_stage2, batch_size=config["training"]["batch_size"], shuffle=True)
    
    # 2. 2ì°¨ í•™ìŠµ ë£¨í”„ (Weighted Training)
    for epoch in range(config["training"]["epochs"]):
        t_loss, t_acc = run_epoch(model_A_prime, train_loader_stage2, optimizer_A_prime, device, "train")
        v_acc, v_loss, _, _, _ = test_multimodal(model_A_prime, test_loader, device, shuffle_mode="none")
        print(f"Ep {epoch+1:02d} (A') | W-Train Acc: {t_acc:.3f}, Loss: {t_loss:.4f} | Test Acc: {v_acc:.3f}")


    # ================= FINAL TEST (Model A') =================
    print("\n\n================ FINAL EVALUATION (Model A') ================")
    
    # ìµœì¢… ëª¨ë¸ A'ì„ ì‚¬ìš©
    final_model = model_A_prime 

    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ (ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
    scenarios = [
        ("1_Normal_Multimodal_Test", "none"),          # ì •ìƒ ë©€í‹°ëª¨ë‹¬ ì„±ëŠ¥
        ("2_Bio_Only_(Text_Masked)", "text_zeroout"), # í…ìŠ¤íŠ¸ ë§ˆìŠ¤í‚¹ (Bio-Only ì„±ëŠ¥ í™•ì¸)
        ("3_Text_Only_(Bio_Masked)", "bio_zeroout")   # Bio ë§ˆìŠ¤í‚¹ (Text-Only ì„±ëŠ¥ í™•ì¸)
    ]

    for name, mode in scenarios:
        print(f"\nğŸ”¶ Running Scenario: {name}")
        
        # 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        acc, loss, labels, preds, probs = test_multimodal(final_model, test_loader, device, shuffle_mode=mode)
        
        print(f"   Test Acc: {acc:.4f}, Loss: {loss:.4f}")
        
        # 2. ê²°ê³¼ ì¶œë ¥ ë° ì‹œê°í™” ì €ì¥ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)
        save_plots_and_report(name, labels, preds, probs) 
        
    print("\nâœ… All stages completed.")


if __name__ == '__main__':
    main()